{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":77807,"databundleVersionId":8765512,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_log_error\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.ensemble import BaggingRegressor\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:27.893112Z","iopub.execute_input":"2024-06-30T09:45:27.893473Z","iopub.status.idle":"2024-06-30T09:45:43.160332Z","shell.execute_reply.started":"2024-06-30T09:45:27.893441Z","shell.execute_reply":"2024-06-30T09:45:43.159364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\ndata = pd.read_csv(\"/kaggle/input/ml-competition-2024-for-ukrainians/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/ml-competition-2024-for-ukrainians/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/ml-competition-2024-for-ukrainians/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:43.162034Z","iopub.execute_input":"2024-06-30T09:45:43.162605Z","iopub.status.idle":"2024-06-30T09:45:45.111761Z","shell.execute_reply.started":"2024-06-30T09:45:43.162575Z","shell.execute_reply":"2024-06-30T09:45:45.110653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test_data.columns:\n    if len(test_data[i].unique())<30:\n        print(i, test_data[i].unique())\n    else: print(i)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:45.112933Z","iopub.execute_input":"2024-06-30T09:45:45.113274Z","iopub.status.idle":"2024-06-30T09:45:45.409638Z","shell.execute_reply.started":"2024-06-30T09:45:45.113245Z","shell.execute_reply":"2024-06-30T09:45:45.408632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_statistics(data):\n    stats = data.groupby(['Item_Type', 'Outlet_Identifier'])['Item_Outlet_Sales'].agg(['mean', 'std', 'min', 'max', 'median', 'count']).reset_index()\n    stats.columns = ['Item_Type', 'Outlet_Identifier', 'IOS_mean', 'IOS_std', 'IOS_min', 'IOS_max', 'IOS_median', 'IOS_count']\n    \n    # Замінюємо NaN значення std на 0\n    stats['IOS_std'].fillna(0, inplace=True)\n    \n    return stats\n\ndef merge_statistics(data, stats):\n    data = pd.merge(data, stats, on=['Item_Type', 'Outlet_Identifier'], how='left')\n    return data\n\ndef preprocess_data(train_data, test_data):\n    # Compute statistics for training data\n    stats = compute_statistics(train_data)\n    \n    # Merge statistics into training and test data\n    train_data = merge_statistics(train_data, stats)\n    test_data = merge_statistics(test_data, stats)\n    \n    # Replace specific values in 'Item_Fat_Content' column\n    train_data.replace(['Regular', 'reg'], 1, inplace=True)\n    train_data.replace(['Low Fat', 'LF', 'low fat'], 0, inplace=True)\n    test_data.replace(['Regular', 'reg'], 1, inplace=True)\n    test_data.replace(['Low Fat', 'LF', 'low fat'], 0, inplace=True)\n    \n    # Add new feature 'Age_of_Outlet'\n    train_data['Age_of_Outlet'] = 2024 - train_data['Outlet_Establishment_Year']\n    test_data['Age_of_Outlet'] = 2024 - test_data['Outlet_Establishment_Year']\n    \n    # Convert categorical variables to dummy variables\n    categorical_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n    train_data = pd.get_dummies(train_data, columns=categorical_cols)\n    test_data = pd.get_dummies(test_data, columns=categorical_cols)\n    \n    # Ensure both train and test datasets have the same dummy variables\n    test_data = test_data.reindex(columns = train_data.columns, fill_value=0)\n    \n    # Fill NaN values in numerical columns with 0 (or other appropriate value)\n    train_data.fillna(0, inplace=True)\n    test_data.fillna(0, inplace=True)\n    \n    # Select numerical features including 'Age_of_Outlet'\n    numerical_cols = ['Age_of_Outlet', 'Item_Weight', 'Item_Visibility','IOS_mean', 'IOS_std', 'IOS_min', 'IOS_max', 'IOS_median', 'IOS_count']\n    X_train_numerical = train_data[numerical_cols]\n    X_test_numerical = test_data[numerical_cols]\n    \n    # Scale numerical features\n    scaler = StandardScaler()\n    X_train_numerical_scaled = scaler.fit_transform(X_train_numerical)\n    X_test_numerical_scaled = scaler.transform(X_test_numerical)\n    \n    # Select categorical features, excluding 'Item_Outlet_Sales', 'id', 'Item_Identifier', 'Outlet_Establishment_Year'\n    exclude_cols = numerical_cols + ['Item_Outlet_Sales', 'id', 'Item_Identifier', 'Outlet_Establishment_Year']\n    X_train_categorical = train_data.drop(columns=exclude_cols)\n    X_test_categorical = test_data.drop(columns=exclude_cols)\n    \n    # Convert boolean values to int\n    X_train_categorical = X_train_categorical.astype(int)\n    X_test_categorical = X_test_categorical.astype(int)\n    \n    # Combine numerical and categorical features\n    X_train = np.hstack([X_train_numerical_scaled, X_train_categorical.values])\n    X_test = np.hstack([X_test_numerical_scaled, X_test_categorical.values])\n    \n    return X_train, X_test","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:45.412651Z","iopub.execute_input":"2024-06-30T09:45:45.413242Z","iopub.status.idle":"2024-06-30T09:45:45.430095Z","shell.execute_reply.started":"2024-06-30T09:45:45.413203Z","shell.execute_reply":"2024-06-30T09:45:45.429039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing the data\nX, test_data = preprocess_data(data, test_data)\ny = data['Item_Outlet_Sales']","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:45.431261Z","iopub.execute_input":"2024-06-30T09:45:45.431575Z","iopub.status.idle":"2024-06-30T09:45:49.089783Z","shell.execute_reply.started":"2024-06-30T09:45:45.431550Z","shell.execute_reply":"2024-06-30T09:45:49.088956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Розділення даних на навчальну (80%) та тестову (20%) вибірки\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=55)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:49.091009Z","iopub.execute_input":"2024-06-30T09:45:49.091376Z","iopub.status.idle":"2024-06-30T09:45:49.347590Z","shell.execute_reply.started":"2024-06-30T09:45:49.091343Z","shell.execute_reply":"2024-06-30T09:45:49.346497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomLearningRateScheduler(Callback):\n    def __init__(self, patience=10, factor=0.5, min_lr=1e-6):\n        super(CustomLearningRateScheduler, self).__init__()\n        self.patience = patience\n        self.factor = factor\n        self.min_lr = min_lr\n        self.best_weights = None\n        self.wait = 0\n        self.best = np.Inf\n\n    def on_train_begin(self, logs=None):\n        self.wait = 0\n        self.best = np.Inf\n        self.best_weights = None\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_loss = logs.get(\"val_loss\")\n        if current_loss is None:\n            return\n        if np.less(current_loss, self.best):\n            self.best = current_loss\n            self.wait = 0\n            self.best_weights = self.model.get_weights()\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                old_lr = float(K.get_value(self.model.optimizer.learning_rate))\n                if old_lr > self.min_lr:\n                    new_lr = old_lr * self.factor\n                    new_lr = max(new_lr, self.min_lr)\n                    self.model.optimizer.learning_rate.assign(new_lr)\n                    print(f\"\\nEpoch {epoch+1}: reducing learning rate to {new_lr}.\")\n                    self.model.set_weights(self.best_weights)\n                    self.wait = 0\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:49.348836Z","iopub.execute_input":"2024-06-30T09:45:49.349192Z","iopub.status.idle":"2024-06-30T09:45:49.360547Z","shell.execute_reply.started":"2024-06-30T09:45:49.349133Z","shell.execute_reply":"2024-06-30T09:45:49.359430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(2048, input_dim=X.shape[1], activation='relu'))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1))\n\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n# Create the custom learning rate scheduler callback\nclr_scheduler = CustomLearningRateScheduler(patience=5, factor=0.5, min_lr=1e-6)\n\n\n# Compile your model\nmodel.compile(optimizer=Adam(learning_rate=0.005), loss='mean_squared_logarithmic_error')\n\n# Train your model with the custom learning rate scheduler\nmodel.fit(X, y, epochs=150, batch_size=64, \n          validation_data=(X_val, y_val), verbose=1, \n          callbacks=[early_stopping, clr_scheduler])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:45:49.361697Z","iopub.execute_input":"2024-06-30T09:45:49.361967Z","iopub.status.idle":"2024-06-30T09:59:13.235185Z","shell.execute_reply.started":"2024-06-30T09:45:49.361944Z","shell.execute_reply":"2024-06-30T09:59:13.234199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on test data\npredictions = model.predict(test_data).flatten()\nsubmission['Item_Outlet_Sales'] = predictions\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(submission_file_path, index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:59:13.237069Z","iopub.execute_input":"2024-06-30T09:59:13.237812Z","iopub.status.idle":"2024-06-30T09:59:29.088118Z","shell.execute_reply.started":"2024-06-30T09:59:13.237767Z","shell.execute_reply":"2024-06-30T09:59:29.087130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозування на валідаційних даних\ny_val_pred = model.predict(X_val)\nmsle_val = mean_squared_log_error(y_val, y_val_pred)\nprint(f'Mean Squared Logarithmic Error (MSLE) on validation set: {msle_val}')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T09:59:29.091239Z","iopub.execute_input":"2024-06-30T09:59:29.091588Z","iopub.status.idle":"2024-06-30T09:59:33.624891Z","shell.execute_reply.started":"2024-06-30T09:59:29.091560Z","shell.execute_reply":"2024-06-30T09:59:33.623538Z"},"trusted":true},"execution_count":null,"outputs":[]}]}